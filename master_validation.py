import pandas as pd
import numpy as np
import joblib # Import joblib for loading models
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, r2_score # Import evaluation metrics

# --- Define Consistent Feature and Target Lists (MUST BE IDENTICAL TO TRAINING SCRIPT - master.py) ---
TARGET = 'target_income'
EXCLUDE_COLS = ['id', TARGET]

categorical_cols_to_convert = [
    'gender', 'marital_status', 'city', 'state', 'residence_ownership',
    'pin',
    'device_model', 'device_category', 'platform', 'device_manufacturer',
    'var_74', 'var_75'
]

# --- EXPANDED FEATURES FOR MASTER MODEL - MUST MATCH master.py ---
master_features_candidate = [
    'behavioral_income',
    'demographic_income',
    'location_income',
    'device_income',
    'age',         # Original key feature
    'var_32',      # Original credit_score feature
    'financial_health_score', # Added: powerful engineered feature
    'total_balance',          # Added: powerful engineered feature
    'avg_credit_util',        # Added: powerful engineered feature
    'loan_to_income_1',       # Added: powerful engineered feature
    'loan_to_income_2',       # Added: powerful engineered feature
]


# --- 1. Load the trained Master model ---
try:
    master_model_pipeline = joblib.load('master_model_pipeline.pkl')
    print("Master model loaded successfully from 'master_model_pipeline.pkl'.")
except FileNotFoundError:
    print("Error: 'master_model_pipeline.pkl' not found.")
    print("Please ensure you have run 'master.py' first to train and save the model.")
    exit()

# --- 2. Load the base validation dataset and slave model predictions for validation ---
try:
    df_validation_base = pd.read_csv('processed_dataset_400.csv')
    print("\nBase validation dataset 'processed_dataset_400.csv' loaded successfully.")

    # Load slave model predictions generated for the validation dataset
    # These CSVs should have been generated by the *_validation.py scripts
    df_val_behavioral = pd.read_csv('processed_dataset_400_with_behavioral_income.csv')
    df_val_demographic = pd.read_csv('processed_dataset_400_with_demographic_income.csv')
    df_val_location = pd.read_csv('processed_dataset_400_with_location_income.csv')
    df_val_device = pd.read_csv('processed_dataset_400_with_device_income.csv')
    print("Slave model predictions for validation set loaded successfully.")

    # --- Explicitly convert categorical columns in validation df to string type ---
    for col in categorical_cols_to_convert:
        if col in df_validation_base.columns:
            df_validation_base[col] = df_validation_base[col].astype(str).replace('nan', np.nan)
    
except FileNotFoundError as e:
    print(f"Error: Required validation file not found - {e}")
    print("Please ensure all 'processed_dataset_400_with_*.csv' files are present (run slave model validations first).")
    exit()

# --- Validate and clean IDs before merging to prevent row duplication ---
# Check for duplicates in the base validation set (should ideally not have any)
if df_validation_base['id'].duplicated().any():
    print("Warning: Duplicate 'id' found in 'processed_dataset_400.csv'. This may affect merging integrity.")
    # Consider dropping duplicates here if 'id' should be truly unique in source.
    # For now, we proceed, but flag it.

# Function to clean slave prediction dataframes for merging
def clean_slave_df(slave_df, name):
    if slave_df['id'].duplicated().any():
        print(f"Warning: Duplicate 'id' found in {name}. Keeping first occurrence for each ID during merge.")
        # Drop duplicates, keeping the first occurrence, to ensure unique IDs for merging
        return slave_df.drop_duplicates(subset=['id'], keep='first').copy()
    return slave_df.copy()

df_val_behavioral = clean_slave_df(df_val_behavioral, 'processed_dataset_400_with_behavioral_income.csv')
df_val_demographic = clean_slave_df(df_val_demographic, 'processed_dataset_400_with_demographic_income.csv')
df_val_location = clean_slave_df(df_val_location, 'processed_dataset_400_with_location_income.csv')
df_val_device = clean_slave_df(df_val_device, 'processed_dataset_400_with_device_income.csv')


# --- 3. Merge slave model predictions into the validation DataFrame ---
df_validation_master = df_validation_base.copy()

# Perform left merges. If slave DFs had duplicates, they are now handled by clean_slave_df.
df_validation_master = pd.merge(df_validation_master, df_val_behavioral[['id', 'behavioral_income']], on='id', how='left')
df_validation_master = pd.merge(df_validation_master, df_val_demographic[['id', 'demographic_income']], on='id', how='left')
df_validation_master = pd.merge(df_validation_master, df_val_location[['id', 'location_income']], on='id', how='left')
df_validation_master = pd.merge(df_validation_master, df_val_device[['id', 'device_income']], on='id', how='left')

print("\nValidation DataFrame after merging slave predictions (head):")
print(df_validation_master[['id', 'target_income', 'behavioral_income', 'demographic_income', 'location_income', 'device_income']].head())
print(f"Total rows in validation master DataFrame (after merge attempt): {len(df_validation_master)}")


# --- 4. Prepare features and target for prediction and evaluation ---
# Re-calculate numerical and categorical features based on the merged validation DataFrame
# and the master_features_candidate list which now includes the new features.
master_features_for_prediction = [col for col in master_features_candidate if col in df_validation_master.columns and col not in EXCLUDE_COLS]

master_numerical_features_val = [col for col in master_features_for_prediction if pd.api.types.is_numeric_dtype(df_validation_master[col])]
master_categorical_features_val = [col for col in master_features_for_prediction if pd.api.types.is_object_dtype(df_validation_master[col]) or pd.api.types.is_string_dtype(df_validation_master[col])]


# Re-create the preprocessor for the validation script to ensure it matches the trained pipeline
# This needs to be done explicitly here as the loaded pipeline doesn't expose these internal details readily.
master_numerical_pipeline_val = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

master_categorical_pipeline_val = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

master_preprocessor_val = ColumnTransformer(
    transformers=[
        ('num', master_numerical_pipeline_val, master_numerical_features_val),
        ('cat', master_categorical_pipeline_val, master_categorical_features_val)
    ],
    remainder='drop',
    verbose_feature_names_out=False
)

# It's generally better to let the loaded pipeline handle all transformations
# But for debugging purposes or explicit feature set verification, this can be useful.
# For direct prediction, the `master_model_pipeline.predict(X_validation_master)`
# will internally call its preprocessor using the features it was trained on.


# Drop rows where TARGET or any of the master features are NaN from the validation set
# This ensures consistency with how the training data was prepared for the Master Model.
df_clean_validation_master = df_validation_master.dropna(subset=[TARGET] + master_features_for_prediction).copy()

# Verify the number of rows after dropping NaNs
print(f"Total rows in clean validation master DataFrame (after NaN drop): {len(df_clean_validation_master)}")


X_validation_master = df_clean_validation_master[master_features_for_prediction].copy()
y_validation_true_master = df_clean_validation_master[TARGET].copy()


# --- 5. Generate 'final_predicted_income' predictions for the validation dataset ---
print("\nGenerating 'final_predicted_income' predictions for the validation dataset...")
y_validation_pred_master = master_model_pipeline.predict(X_validation_master)

# Ensure predictions are non-negative
y_validation_pred_master[y_validation_pred_master < 0] = 0
df_clean_validation_master['final_predicted_income'] = y_validation_pred_master


# --- 6. Evaluate the Master Model on the validation set ---
print("\nMaster Model Evaluation on Validation Set:")
validation_mae_master = mean_absolute_error(y_validation_true_master, y_validation_pred_master)
validation_r2_master = r2_score(y_validation_true_master, y_validation_pred_master)

print(f"Mean Absolute Error (MAE) on Validation Set: ${validation_mae_master:,.2f}")
print(f"R-squared (R2) Score on Validation Set: {validation_r2_master:.4f}")


# --- 7. Save the updated validation dataset ---
print("\nValidation DataFrame with 'final_predicted_income' column:")
print(df_clean_validation_master[['id', 'target_income', 'behavioral_income', 'demographic_income', 'location_income', 'device_income', 'final_predicted_income']].head())
print(f"Number of rows with 'final_predicted_income' predictions: {df_clean_validation_master['final_predicted_income'].count()}")

output_validation_filename_master = 'processed_dataset_400_with_all_final_predictions.csv'
df_clean_validation_master.to_csv(output_validation_filename_master, index=False)
print(f"\nUpdated validation dataset saved to '{output_validation_filename_master}'")

print("\nMaster Model validation process complete.")
